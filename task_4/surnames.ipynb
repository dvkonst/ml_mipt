{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.907896663061\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, metrics, linear_model, svm\n",
    "from sklearn.feature_extraction.text import FeatureHasher, TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "import scipy.sparse as ss\n",
    "\n",
    "raw_train = pd.read_csv('linear_train.txt', header=None)\n",
    "fff_test = pd.read_csv('linear_test.txt', header=None)\n",
    "f = np.vectorize(lambda x: x[-7:]) # вся нужная информация в конце слов\n",
    "slow = np.vectorize(str.lower) # неодинаковый регистр все портит\n",
    "suffs = slow(f(raw_train[0].values))\n",
    "\n",
    "# генерация признаков: есть или нет определенная подстрока в суффиксе слова\n",
    "cv = CountVectorizer(ngram_range=(1, 6), lowercase=False, analyzer='char_wb')\n",
    "model_cv = cv.fit(suffs)\n",
    "data_train = model_cv.transform(suffs)\n",
    "data_test = model_cv.transform(fff_test[0].values)\n",
    "\n",
    "# признаки слов с большой буквы и написанных CAPS'ом\n",
    "new_train = ss.hstack((data_train, pd.DataFrame(list(map(lambda x: 1.0 if x.istitle() else 0.0, raw_train[0].values)))))\n",
    "new_test = ss.hstack((data_test, pd.DataFrame(list(map(lambda x: 1.0 if x.istitle() else 0.0, fff_test[0].values)))))\n",
    "new_train = ss.hstack((new_train, pd.DataFrame(list(map(lambda x: 1.0 if x.isupper() else 0.0, raw_train[0].values)))))\n",
    "new_test = ss.hstack((new_test, pd.DataFrame(list(map(lambda x: 1.0 if x.isupper() else 0.0, fff_test[0].values)))))\n",
    "\n",
    "# классификация с помощью линейной модели\n",
    "new_y_train = raw_train[1]\n",
    "model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', C=1.)\n",
    "print(model_selection.cross_val_score(model, new_train, new_y_train, \n",
    "                                      scoring='roc_auc', cv=model_selection.StratifiedKFold(shuffle=True)).mean())\n",
    "# предсказания на тестовой выборке\n",
    "model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', C=1.)\n",
    "model.fit(new_train, new_y_train)\n",
    "pred = model.predict_proba(new_test)[:, 0]\n",
    "ans = pd.DataFrame()\n",
    "ans[\"Id\"] = range(len(pred))\n",
    "ans[\"Answer\"] = pred\n",
    "ans.to_csv('res4.txt', sep=',', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# file = open('text.txt', 'r')\n",
    "# lo = list(map(lambda x: [x[0], float(x[1])], map(lambda x: x.split(', '), map(str.rstrip, file.readlines()))))\n",
    "# file.close()\n",
    "# lo\n",
    "\n",
    "# raw = pd.DataFrame(lo)\n",
    "# f = np.vectorize(lambda x: x[-5:])\n",
    "# slow = np.vectorize(str.lower)\n",
    "# suffs = slow(f(raw[0].values))\n",
    "# clses = raw[1].values\n",
    "# # list(map(lambda x: x[-4:], raw[0].values))\n",
    "# suffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # from numba import vectorize\n",
    "# class Features():\n",
    "#     def __init__(self, nsn, nal):\n",
    "#         self.D = {}\n",
    "#         self.nsn = nsn\n",
    "#         self.nal = nal\n",
    "#         self.nt = nal - nsn\n",
    "        \n",
    "# #     @vectorize\n",
    "#     def dicinc(self, x, cl):\n",
    "# #         x, cl = w\n",
    "#         try:\n",
    "#             y = self.D[x]\n",
    "#             y[0] += 1\n",
    "#             if cl == 1.0:\n",
    "#                 y[1] += 1 #if cl == 1.0 else -1\n",
    "#         except KeyError:\n",
    "#             self.D[x] = [1, 1] #if cl == 1.0 else [1, -1]\n",
    "# #     @vectorize\n",
    "#     def spliter(self, x, cl, ps=2):\n",
    "#         l = len(x)\n",
    "#         for i in range(0, l - ps + 1):\n",
    "#              self.dicinc(x[i:i+ps], cl)\n",
    "#     def dicsort(self):\n",
    "#         for key in self.D:\n",
    "#             y = self.D[key]\n",
    "#             a1 = y[1]\n",
    "#             a0 = y[0] - y[1]\n",
    "#             b1 = self.nsn - y[1]\n",
    "#             b0 = self.nt - a0\n",
    "#             y[1] = (a1*b0 - a0*b1) / self.nal / self.nal\n",
    "#     def tolist(self):\n",
    "#         l = list(map(lambda x: (self.D[x])[1], self.D))\n",
    "# #         print(l)\n",
    "#         l.sort()\n",
    "#         return l, l[0:5], l[-5:-1]\n",
    "#     def get_feature(self, x, ps=2):\n",
    "#         wl = []\n",
    "# #         x.lower()\n",
    "#         l = len(x)\n",
    "#         for i in range(0, l - ps + 1):\n",
    "#             fr = x[i:i+ps]\n",
    "#             try:\n",
    "#                 y = self.D[fr]\n",
    "#                 wl.append(y[1])\n",
    "#             except KeyError:\n",
    "#                 continue\n",
    "# #         wl.sort()\n",
    "#         if len(wl) == 0:\n",
    "#             return 0.0\n",
    "# #         ma = np.mean(np.array(wl))\n",
    "#         ma = max(wl)\n",
    "#         return ma if ma >= 0.0 else min(wl)\n",
    "    \n",
    "            \n",
    "# spliter('ва')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file = open('linear_train.txt', 'r')\n",
    "# lo = list(map(lambda x: [x[0], float(x[1])], map(lambda x: x.split(', '), map(str.rstrip, file.readlines()))))\n",
    "# file.close()\n",
    "# raw = pd.DataFrame(lo)\n",
    "# f = np.vectorize(lambda x: x[-5:])\n",
    "# slow = np.vectorize(str.lower)\n",
    "# suffs = slow(f(raw[0].values))\n",
    "# # suffs = f(raw[0].values)\n",
    "# clses = raw[1].values\n",
    "\n",
    "# F = Features(np.sum(clses), clses.size)\n",
    "# # F.spliter(suffs, clses)\n",
    "# list(map(lambda x, y: F.spliter(x, y), suffs, clses))\n",
    "# # F.D\n",
    "# F.dicsort()\n",
    "# l, mi, ma = F.tolist()\n",
    "# print(mi, ma)\n",
    "# # F.D['ин']\n",
    "# # print(F.nsn, F.nal)\n",
    "# gf = np.array(list(map(F.get_feature, suffs)))\n",
    "# ma = np.amax(gf)\n",
    "# mi = np.amin(gf)\n",
    "# # print(ma)\n",
    "# feres = pd.DataFrame({'5_2': gf})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for key in F.D:\n",
    "#     y = F.D[key]\n",
    "#     if y[1] >= 0.001:\n",
    "#         print(key, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fff = pd.read_csv('linear_test.txt', header=None)\n",
    "# fff\n",
    "# # file = open('linear_test.txt', 'r')\n",
    "# # lo = list(map(lambda x: [x[0], float(x[1])], map(lambda x: x.split(', '), map(str.rstrip, file.readlines()))))\n",
    "# # file.close()\n",
    "# # raw = pd.DataFrame(lo)\n",
    "# f = np.vectorize(lambda x: x[-5:])\n",
    "# slow = np.vectorize(str.lower)\n",
    "# # suffs = slow(f(raw[0].values))\n",
    "# # f = np.vectorize(lambda x: x[-5:])\n",
    "# suffs = slow(f(fff[0].values))\n",
    "# # clses = fff[1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
    "# from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "# from sklearn.svm import SVC\n",
    "# import matplotlib.pyplot as plt\n",
    "# X = gf.reshape((gf.size, 1))\n",
    "# Y = clses\n",
    "# # X_test = np.array(list(map(F.get_feature, suffs)))\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "# clf = linear_model.SGDClassifier(loss='log', penalty='none')\n",
    "# # clf = SVC()\n",
    "\n",
    "# # clf.fit(X_train, y_train)\n",
    "# # y_score = clf.decision_function(X_test.reshape((X_test.size, 1)))\n",
    "# # print(y_score)\n",
    "# # fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "# # roc_auc = auc(fpr, tpr)\n",
    "# # print(roc_auc)\n",
    "# # plt.plot(fpr, tpr)\n",
    "# # plt.show()\n",
    "# print(cross_val_score(clf, X_train, y_train, \n",
    "#                                       scoring='roc_auc', cv=StratifiedKFold(shuffle=True)).min())\n",
    "# # y_pred = cross_val_predict(clf, X_train, y_train, cv=10)\n",
    "# # accuracy_score(y_test, y_pred)\n",
    "# # res = pd.DataFrame(y_pred)\n",
    "# # res.to_csv('res1.txt')\n",
    "# # print(y_test.size, y_pred.size)\n",
    "# # print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file = open('linear_train.txt', 'r')\n",
    "# lo = list(map(lambda x: [x[0], float(x[1])], map(lambda x: x.split(', '), map(str.rstrip, file.readlines()))))\n",
    "# file.close()\n",
    "# raw = pd.DataFrame(lo)\n",
    "# clses = raw[1].values\n",
    "# slow = np.vectorize(str.lower)\n",
    "\n",
    "# fff_test = pd.read_csv('linear_test.txt', header=None)\n",
    "\n",
    "# for j in [2, 3, 4, 5]:\n",
    "#     for i in range(6, j - 1, -1):\n",
    "#         f = np.vectorize(lambda x: x[-i:])\n",
    "#         suffs = slow(f(raw[0].values))\n",
    "#         suffs_t = slow(f(fff_test[0].values))\n",
    "#         F = Features(np.sum(clses), clses.size)\n",
    "#         list(map(lambda x, y: F.spliter(x, y, ps=j), suffs, clses))\n",
    "#         F.dicsort()\n",
    "#         # l, mi, ma = F.tolist()\n",
    "#         # print(mi, ma)\n",
    "#         gf = np.array(list(map(lambda x: F.get_feature(x, ps=j), suffs)))\n",
    "#         gf_t = np.array(list(map(lambda x: F.get_feature(x, ps=j), suffs_t)))\n",
    "#         raw['r'+str(i)+'_'+str(j)] = pd.DataFrame(gf)\n",
    "#         fff_test['r'+str(i)+'_'+str(j)] = pd.DataFrame(gf_t)\n",
    "\n",
    "# tit = np.array(list(map(lambda x: 1.0 if x.istitle() else 0.0, raw[0].values)))\n",
    "# raw['tit'] = pd.DataFrame(tit)\n",
    "# tit = np.array(list(map(lambda x: 1.0 if x.istitle() else 0.0, fff_test[0].values)))\n",
    "# fff_test['tit'] = pd.DataFrame(tit)\n",
    "\n",
    "# caps = np.array(list(map(lambda x: 1.0 if x.isupper() else 0.0, raw[0].values)))\n",
    "# raw['caps'] = pd.DataFrame(caps)\n",
    "# caps = np.array(list(map(lambda x: 1.0 if x.isupper() else 0.0, fff_test[0].values)))\n",
    "# fff_test['caps'] = pd.DataFrame(caps)\n",
    "\n",
    "# raw.head()\n",
    "# fff_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "# from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# X = raw.drop([0, 1], axis=1).values\n",
    "# Y = clses\n",
    "# # X_test = np.array(list(map(F.get_feature, suffs)))\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, Y, test_size=0.1)#, random_state=42)\n",
    "\n",
    "# clf = linear_model.SGDClassifier(loss='log', penalty='l1')\n",
    "# # clf = linear_model.LogisticRegression(penalty='l2')\n",
    "# print(cross_val_score(clf, X_train, y_train, \n",
    "#                                       scoring='roc_auc', cv=StratifiedKFold(shuffle=True)).min())\n",
    "\n",
    "# clf = GradientBoostingClassifier(n_estimators=150, random_state=42, max_depth=5)\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_score = clf.decision_function(X_test)\n",
    "# # print(y_score)\n",
    "# fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print(roc_auc)\n",
    "# plt.plot(fpr, tpr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fff = pd.read_csv('linear_test.txt', header=None)\n",
    "# # fff\n",
    "# # file = open('linear_test.txt', 'r')\n",
    "# # lo = list(map(lambda x: [x[0], float(x[1])], map(lambda x: x.split(', '), map(str.rstrip, file.readlines()))))\n",
    "# # file.close()\n",
    "# # raw = pd.DataFrame(lo)\n",
    "# f = np.vectorize(lambda x: x[-5:])\n",
    "# slow = np.vectorize(str.lower)\n",
    "# # suffs = slow(f(raw[0].values))\n",
    "# # f = np.vectorize(lambda x: x[-5:])\n",
    "# suffs = slow(f(fff[0].values))\n",
    "# # clses = fff[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import linear_model\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "# from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "# X = raw.drop([0, 1], axis=1).values\n",
    "# X_t = fff_test.drop([0], axis=1).values\n",
    "# Y = clses\n",
    "\n",
    "# # clf = linear_model.SGDClassifier(loss='log', penalty='l1')\n",
    "# # clf = linear_model.LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "# # clf = GradientBoostingClassifier(n_estimators=200, random_state=42, max_depth=5)\n",
    "# # clf.fit(X, Y)\n",
    "# # y_pred = clf.predict_proba(X_t)#[:, 0]\n",
    "# # res = pd.DataFrame({y_pred})\n",
    "# # res.to_csv('res3.txt')\n",
    "# # print(y_test.size, y_pred.size)\n",
    "# model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', C=0.75)\n",
    "# model.fit(X, Y)\n",
    "# pred = model.predict_proba(X_t)[:, 0]\n",
    "# ans = pd.DataFrame()\n",
    "# ans[\"Id\"] = range(len(pred))\n",
    "# ans[\"Answer\"] = pred\n",
    "# ans.to_csv('res5.txt', sep=',', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn import model_selection, metrics, linear_model, svm\n",
    "# from sklearn.feature_extraction.text import FeatureHasher, TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "# import scipy.sparse as ss\n",
    "\n",
    "# raw_train = pd.read_csv('linear_train.txt', header=None)\n",
    "# fff_test = pd.read_csv('linear_test.txt', header=None)\n",
    "# f = np.vectorize(lambda x: x[-5:])\n",
    "# slow = np.vectorize(str.lower)\n",
    "# suffs = slow(f(raw_train[0].values))\n",
    "# cv = CountVectorizer(ngram_range=(2, 4), lowercase=False, analyzer='char_wb')\n",
    "# model_cv = cv.fit(suffs)\n",
    "# data_train = model_cv.transform(suffs)\n",
    "# data_test = model_cv.transform(fff_test[0].values)\n",
    "# # data_train.shape\n",
    "# # tit = np.array(list(map(lambda x: 1.0 if x.istitle() else 0.0, raw_train[0].values)))\n",
    "# # data_train['tit'] = pd.DataFrame(tit)\n",
    "# new_train = ss.hstack((data_train, pd.DataFrame(list(map(lambda x: 1.0 if x.istitle() else 0.0, raw_train[0].values)))))\n",
    "# new_test = ss.hstack((data_test, pd.DataFrame(list(map(lambda x: 1.0 if x.istitle() else 0.0, fff_test[0].values)))))\n",
    "# new_train = ss.hstack((new_train, pd.DataFrame(list(map(lambda x: 1.0 if x.isupper() else 0.0, raw_train[0].values)))))\n",
    "# new_test = ss.hstack((new_test, pd.DataFrame(list(map(lambda x: 1.0 if x.isupper() else 0.0, fff_test[0].values)))))\n",
    "\n",
    "# new_y_train = raw_train[1]\n",
    "# model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', C=1.)\n",
    "# # model = GradientBoostingClassifier()\n",
    "# print(model_selection.cross_val_score(model, new_train, new_y_train, \n",
    "#                                       scoring='roc_auc', cv=model_selection.StratifiedKFold(shuffle=True)).mean())\n",
    "# model = linear_model.LogisticRegression(penalty='l2', solver='lbfgs', C=1.)\n",
    "# model.fit(new_train, new_y_train)\n",
    "# pred = model.predict_proba(new_test)[:, 0]\n",
    "# ans = pd.DataFrame()\n",
    "# ans[\"Id\"] = range(len(pred))\n",
    "# ans[\"Answer\"] = pred\n",
    "# ans.to_csv('res4.txt', sep=',', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
